<!DOCTYPE html>
<html lang="en">

<head>
   <title>Data Leakage</title>
   <link rel="stylesheet" href="./css/main.css">
</head>

<body>
   <div class="topnav">
      <div class="heading">
         <h1>Data Leakage</h1>
      </div>
      <div class="menu">
         <a href="./pages/about-us/">About the team</a>
         <a class="active" href="./">About the project</a>
         <a href="./pages/design/">Design</a>
         <a href="./pages/tasks/">Tasks</a>
         <a href="./pages/resources/">Resources</a>

      </div>
   </div>



   <div class="project-description">
      <h2>Project Description</h2>
      <p>
         Code quality is of paramount importance in all types of software development settings. 
         Our project seeks to enable machine learning (ML) engineers to write better code by helping them find and fix instances of Data Leakage in their models. 
         Data Leakage is a problem where an ML model is unintentionally trained on data that is not present in the training dataset. 
         As a result, the model effectively "memorizes" the data it trains on, leading to an overly optimistic estimate of model performance and an inability to make generalized predictions. 
         To avoid introducing Data Leakage into their code, ML developers must carefully separate their data into training, evaluation, and test sets. 
         Training data should be used to train the model, evaluation data should be used to confirm the accuracy of a model repeatedly, and test data should be used only once to determine the accuracy of a production-ready model. 
         According to the paper Data Leakage in Notebooks: Static Detection and Better Processes, many model designers do not effectively separate their testing data from their evaluation and training data. 
         We are developing a plugin for the PyCharm IDE that identifies instances of data leakage in ML code and provides suggestions on how to remove the leakage. 
      </p>
      <p>Source: Yang, C., Brower-Sinning, R. A., Lewis, G., & KÃ¤stner, C. (2022). <i>Data leakage in notebooks: Static
            detection and Better Processes.</i> Proceedings of the 37th IEEE/ACM International Conference on Automated
         Software Engineering. https://doi.org/10.1145/3551349.3556918 </p>
      <h3>Team Members (from left to right)</h3>
      <p>
         Suneedhi Laddha, Roger Shagawat, Brandon Kreiser, Catherine DeMario, Cindy Tran, Karina Berberian
      </p>

      <div class="image">
         <img src="./images/seniordesignpic.jpg" alt="Senior Design Pic" height="500" widht="1000">
      </div>
   
   </div>

   <div>
      <h4>Github Link For Data Leakage Plugin</h4>
      <h5>Current Release</h5>
      <a href="https://drive.google.com/file/d/12Tyu673zj0PBlXw9Q1FfcEXQ2vNdbif-/view?usp=sharing">Data Leakage Plugin 1.0.5 Community</a>
      <br>
      <a href="https://drive.google.com/file/d/1RgDk39F2KCV29IbcGJ6iMnmclDAXfw_P/view?usp=sharing">Data Leakage Plugin 1.0.5 Professional</a>
      <p>
         Shall Be Updated Soon With Next Release.
      </p>
   </div>

   <div class="image">
      <h4>Poster Design</h4>
      <a href="https://lh3.googleusercontent.com/drive-viewer/AKGpihZiaBwSo9v4NqAUZN_mb6MCtRLeZTKt0-qpey04oXazBEsAc6x6KmnjBUD-95lNXHAxEETOzeLiXgysz286ndC9E1Xb0JSy6RM=s1600-rw-v1?source=screenshot.guru"> <img src="https://lh3.googleusercontent.com/drive-viewer/AKGpihZiaBwSo9v4NqAUZN_mb6MCtRLeZTKt0-qpey04oXazBEsAc6x6KmnjBUD-95lNXHAxEETOzeLiXgysz286ndC9E1Xb0JSy6RM=s1600-rw-v1" width="1000" height="700"/> </a>
   </div>

   <div>
      <h4>More Information on Types of Leakage</h4>
      <ul>
         <li>
            <a href="./pages/leakage/multi-test/">Multi-Test Leakage</a>
         </li>
         <li>
            <a href="./pages/leakage/overlap/">Overlap Leakage</a>
         </li>
         <li>
            <a href="./pages/leakage/preprocessing/">Preprocessing Leakage</a>
         </li>
      </ul>
      </div>
</body>

</html>