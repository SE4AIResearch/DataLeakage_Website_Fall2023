<!DOCTYPE html>
<html lang="en">

<head>
   <title>Data Leakage</title>
   <link rel="stylesheet" href="./css/main.css">
</head>

<body>
   <div class="topnav">
      <div class="heading">
         <h1>Data Leakage</h1>
      </div>
      <div class="menu">
         <a href="./pages/about-us/">About the team</a>
         <a class="active" href="./">About the project</a>
         <a href="./pages/design/">Design</a>
         <a href="./pages/tasks/">Tasks</a>
         <a href="./pages/resources/">Resources</a>

      </div>
   </div>



   <div class="project-description">
      <h2>Project Description</h2>
      <p>
         Bad coding practices don't only happen in software development settings.
         Code written to train and evaluate machine learning (ML)
         models may contain bugs just like software code. Various forms of <i>data leakage</i>,
         such indistinguishable training and test data, can lead to an overestimation of a model's
         accuracy, which in turn can lead to the deployment of a low quality model.
         Low quality models can do harm to the people that are supposed to benefit from them. There are several
         real-world examples of poor quality models that have been responsible for discrimination and death.
         Amazon had to stop using a recruiting tool that was created with ML because it showed bias against women.
         A Tesla vehicle on autopilot once ran a red light and killed two people.
         There is no question that ML engineers have a duty to produce high quality models and avoid bad coding
         practices
         that cause data leakage.
         Unfortunately, however, data leakage can be difficult to detect. Therefore, we aim to develop a tool (more
         specifically, an IDE plugin) that can detect common
         forms of data leakage in ML code.
      </p>
      <p>Source: Yang, C., Brower-Sinning, R. A., Lewis, G., & KÃ¤stner, C. (2022). <i>Data leakage in notebooks: Static
            detection and Better Processes.</i> Proceedings of the 37th IEEE/ACM International Conference on Automated
         Software Engineering. https://doi.org/10.1145/3551349.3556918 </p>
      <h3>Team Members</h3>
      <p>
         Karina Berberian, Catherine DeMario, Brandon Kreiser, Suneedhi Laddha,
         Roger Shagawat, Cindy Tran
      </p>
   </div>

   <div>
      <h4>Github Link For Data Leakage Plugin</h4>
      <h5>Current Release</h5>
      <a href="https://drive.google.com/file/d/1XRmmLDVbcSGwdr5805fDUW9w8khndjOz/view?usp=sharing">Data Leakage Plugin 1.0.2</a>
      <p>
         Shall Be Updated Soon With Next Release.
      </p>
   </div>

   <div>
      <h4>More Information on Types of Leakage</h4>
      <ul>
         <li>
            <a href="./pages/leakage/multi-test/">Multi-Test Leakage</a>
         </li>
         <li>
            <a href="./pages/leakage/overlap/">Overlap Leakage</a>
         </li>
         <li>
            <a href="./pages/leakage/preprocessing/">Preprocessing Leakage</a>
         </li>
      </ul>
      </div>
</body>

</html>