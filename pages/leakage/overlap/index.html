<!DOCTYPE html>
<html lang="en">

<head>
   <title>Data Leakage - Fall 2023</title>
   <link rel="stylesheet" href="../../../css/main.css">
</head>

<body>
   <div class="topnav">
      <div class="heading">
         <h1>Data Leakage - Fall 2023</h1>
      </div>
      <div class="menu">
         <a href="./pages/about-us/">About the team</a>
         <a class="active" href="../../../index.html">About the project</a>
         <a href="./pages/design/">Design</a>
         <a href="./pages/tasks/">Tasks</a>
         <a href="./pages/resources/">Resources</a>

      </div>
   </div>
      <main>
         <h2>Overlap Leakage:</h2>
         <h3>What is Overlap Leakage?</h3>
         <p>
            Overlap leakage refers to a situation in which there is
            unintentional sharing or overlap of information between the training
            and testing datasets in a machine learning model.
         </p>

         <h3>Causes of overlap leakage:</h3>
         <p>
            This can occur when the same or highly similar data points are
            present in both the training and testing sets. When the model is
            trained on a dataset that shares information with the test set, it
            may lead to overly optimistic performance evaluations and may not
            generalize well to new, unseen data.
         </p>

         <h3>Solutions for overlap leakage:</h3>
         <ul>
            <li>
               Randomized Splitting: Use a randomized approach when splitting
               the dataset into training and testing sets. This helps ensure
               that instances in the training set are not overly similar to
               instances in the test set.
            </li>

            <li>
               Stratified Sampling: If the dataset has class imbalances, use
               stratified sampling to maintain the distribution of classes in
               both the training and testing sets. This can help prevent
               situations where certain classes are overrepresented or
               underrepresented in one of the sets.
            </li>

            <li>
               Temporal Splitting: If the data has a temporal dimension, split
               the dataset based on time. The training set should include data
               from earlier time periods, while the testing set should include
               data from later time periods. This helps simulate a more
               realistic scenario where the model needs to generalize to future,
               unseen data.
            </li>

            <li>
               Geographical Splitting: In some cases, especially in spatial
               data, geographical splitting can be useful. Ensure that instances
               from specific geographical regions are present in either the
               training or testing set but not in both.
            </li>
         </ul>

         <p>
            Managing the split between the training and testing datasets means
            reducing the risk of overlap leakage and obtaining more reliable
            performance evaluations for ML model.
         </p>

         <h3>Example of Overlap Leakage Code</h3>
         <code>
            this is overlap leakage code
         </code>

         <div class="nav">
            <h4>Other types of leakage:</h4>
            <ul>
               <li>
                  <a href="../multi-test/">Multi-Test Leakage</a>
               </li>
               <li>
                  <a href="../preprocessing/">Preprocessing Leakage</a>
               </li>
            </ul>
         </div>
      </main>

      <script src="" async defer></script>
   </body>
</html>
