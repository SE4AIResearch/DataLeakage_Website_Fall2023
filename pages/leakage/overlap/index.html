<!DOCTYPE html>
<html lang="en">

<head>
   <title>Data Leakage - Fall 2023</title>
   <link rel="stylesheet" href="../../../css/main.css">
</head>

<body>
   <div class="topnav">
      <div class="heading">
         <h1>Data Leakage - Fall 2023</h1>
      </div>
      <div class="menu">
         <a href="../../about-us/">About the team</a>
         <a class="active" href="../../../index.html">About the project</a>
         <a href="../../design/">Design</a>
         <a href="../../tasks/">Tasks</a>
         <a href="../../resources/">Resources</a>
      </div>
   </div>
      <main>
         <h2>Overlap Leakage:</h2>
         <h3>What is Overlap Leakage?</h3>
         <p>
            Overlap leakage refers to a situation in which there is
            unintentional sharing or overlap of information between the training
            and testing datasets in a machine learning model.
         </p>

         <h3>Causes of overlap leakage:</h3>
         <p>
            This can occur when the same or highly similar data points are
            present in both the training and testing sets. When the model is
            trained on a dataset that shares information with the test set, it
            may lead to overly optimistic performance evaluations and may not
            generalize well to new, unseen data.
         </p>

         <h3>Solutions for overlap leakage:</h3>
         <ul>
            <li>
               Randomized Splitting: Use a randomized approach when splitting
               the dataset into training and testing sets. This helps ensure
               that instances in the training set are not overly similar to
               instances in the test set.
            </li>

            <li>
               Stratified Sampling: If the dataset has class imbalances, use
               stratified sampling to maintain the distribution of classes in
               both the training and testing sets. This can help prevent
               situations where certain classes are overrepresented or
               underrepresented in one of the sets.
            </li>

            <li>
               Temporal Splitting: If the data has a temporal dimension, split
               the dataset based on time. The training set should include data
               from earlier time periods, while the testing set should include
               data from later time periods. This helps simulate a more
               realistic scenario where the model needs to generalize to future,
               unseen data.
            </li>

            <li>
               Geographical Splitting: In some cases, especially in spatial
               data, geographical splitting can be useful. Ensure that instances
               from specific geographical regions are present in either the
               training or testing set but not in both.
            </li>
         </ul>

         <p>
            Managing the split between the training and testing datasets means
            reducing the risk of overlap leakage and obtaining more reliable
            performance evaluations for ML model.
         </p>

         <h3>Example of Overlap Leakage Code Displayed Below</h3>
         <p>
            Introducing overlap leakage means modifying the splitting process to ensure that some data points are shared between the training and testing sets. This can be achieved by customizing the splitting logic to include overlapping samples between the sets.
            <ul>
               <li>The dataset is split into a training set (80%) and a testing set (20%) with overlap leakage intentionally introduced.</li>
               <li>The last 20% of the dataset is used for testing, with the first 10% of that portion being used as a validation set.</li>
               <li>Tokenization and padding are performed separately for each split after the dataset is split into training, validation, and test sets.</li>
            </ul>
            By taking a portion of the testing set as the validation set and updating the testing set accordingly, we introduce overlap leakage intentionally. This means that some data points are shared between the training, validation, and testing sets, potentially leading to biased model evaluations.
         </p>
         
         <script src="https://gist.github.com/cindy795tran/75bf0342834ce215ed7d37a0dd8827ac.js"></script>

         <h3>Fix Overlap Leakage Displayed Below</h3>
         <p>
            Fix overlap leakage using randomized splitting. Revert to using the train_test_split function from scikit-learn, which ensures that the splitting is randomized.
            <ul>
               <li>The dataset is split into training, validation, and testing sets using train_test_split with a test size of 20% and a validation size of 10%. Random state is set for reproducibility.</li>
               <li>Tokenization and padding are performed separately for each split after the dataset is split into training, validation, and test sets.</li>
               <li>Randomized splitting ensures that the data points are randomly shuffled and divided into the desired sets, preventing any systematic bias or overlap leakage.</li>
            </ul>
         </p>

         <script src="https://gist.github.com/cindy795tran/3b408a2c8870d2316f565505f47d2bd2.js"></script>
         
         <div class="nav">
            <h4>Other types of leakage:</h4>
            <ul>
               <li>
                  <a href="../multi-test/">Multi-Test Leakage</a>
               </li>
               <li>
                  <a href="../preprocessing/">Preprocessing Leakage</a>
               </li>
            </ul>
         </div>
      </main>

      <script src="" async defer></script>
   </body>
</html>
